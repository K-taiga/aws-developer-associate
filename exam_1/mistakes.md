## 質問3
>A社ではアプリケーション開発においてAWSのcodeシリーズと呼ばれるAWS CodeCommitとAWS CodeDeployなどを利用して開発・テスト・デプロイまでのパイプラインを利用したCI/CDを整備しています。CodeDeployによってデプロイを実行した際に、デプロイが成功したかどうかを担当者が確認することが必要です。

>この要件を達成するためにCodeDeployの設定において、実施すべき対応を選択してください。

*A: .appspecファイルをルートディレクトリに定義する*

***
note:

* .appspecファイルをルートディレクトリに定義することで、CodeCommitとCodeDeployの設定に対して、アプリケーションのデプロイ時にファイルへのアクセス許可を変更して、デプロイを制御することができるようになる
* CodeDeployの設定は.appspecファイル
* AppSpec は AWS CodeDeploy で実行するデプロイ処理の内容を設定するYAML ファイル


## 質問4

>あるベンチャー企業ではAWSを利用したCI/CD環境を構築しています。開発環境などはAmazon ECSを利用して全てDocker形式で展開できるようにしています。あなたは開発担当者として、コンテナの設定としてタスクの割り当てを別々に設定したいと考えております。コンテナーのタスク割り当てで資格情報を分割する方法が必要です。

>この設定のために、どのアクションを実行することが必要となりますか？

*A: ECSに対してIAMロールを作成してタスクに割り当てる*

***
note:

* Amazon ECSにおいてコンテナが別のタスクに属する別のコンテナの資格情報へのアクセスを制御するにはアクセス許可の設定が必要（各コンテナには各ロールが必要ってこと）
* ECSのコンテナエージェントはユーザーに代わってECS APIを実行するためにIAMロールが必要
* このIAMロールはタスク実行IAMロールという
* 複数のタスク実行ロールを、アカウントに関連付けることができECSのタスクを複数実行できるようになる

## 質問7

>あなたの会社では顧客データを保存するためにAmazon S3を利用しています。顧客データはセキュリティを強固にする必要があるため、アクセスログを有効にしてステータスについて確認できるような設定をしました。バケットのデータ増加は一週間で1GBほどですが、アクセスログをオン後にバケットのサイズが３日で10GB増加したようです。

>このデータ増加の原因として考えられる要因を説明してください。

*A: サーバーアクセスログはS3バケットを利用するだけでもアクセスログを増加させる*

***
note:

* サーバーアクセスログはストレージデータの増加がデメリット
* サーバーアクセスログはアクセスログのレコードごとに 1 つのアクセスリクエストの詳細として、リクエスタ、バケット名、リクエスト時刻、リクエストアクション、レスポンスのステータス、エラーコード (存在する場合) などの情報が取り込まれる。 ソースバケットとターゲットバケットが同じである場合、バケットに書き込まれるログに関する追加のログが作成される。これにより、利用が頻繁であればあるほどS3バケットにログデータが追加される
つまりソースとそれに対するアクセスログが自分自身の場合には2倍のアクセスログになるということ

## 質問9
>A社では社内の文書共有システムとしてS3をストレージに利用しています。社内の方針で個人PCに保存しているドキュメントを個人管理用のストレージエリアに保存することが決定されました。そのためには、AWSアカウントによって定義されたユーザー全てに、S3バケットに個人用の保存スペースを設定することが必要です。

>この個人用スペースをセットアップする最適な方法を選択してください。

***
note:

*A: 動的変数を使用してIAMポリシーを一つ作成し、全てのユーザーの属するIAMグループにアタッチする*

* 動的変数を使用してIAMポリシーを1つ作成し（一個のルール）、全てのユーザーの属するIAMグループにアタッチすること（全員にそれを反映）でS3バケットに個人用スペースをセットアップすることができる
* IAMポリシーのJSONに各ユーザーに適用できるような動的変数を使用したIAMポリシーを設定して、S3バケットにおいてS3バケット個人用スペースの読み取り、および書き込みの許可を与える

## 質問10
>あなたはAWS専門のエンジニアとして、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリケーションを構築しました。このアプリケーションは、EC2インスタンスでKCLベースでKinesisと連携しています。最近になって利用ユーザーが増加したことで、Kinesis Data Streamにおけるトラフィックが増加したため、あなたはシャードを分割して6シャードから10シャードに増強しました。

>シャードを処理するためにデプロイできるEC2インスタンスの最大数はいくつですか？

*A: 10*

***
note:

* Kinesisはシャードからなるストリームを作成してストリーミングデータを保持して処理する
* 1シャードにつき1EC2を割り当てられるため、10になる

## 質問11
>あなたはAWS専門のエンジニアとして、AWSリソースのセットアップを実施しています。あなたはアプリケーションCLIオプションの設定で、DynamoDBのアプリケーション上の読み込み設定を行っています。DynamoDBスキャンを実行し、特定の属性サブセットを取得する対応が必要です。

>この操作を完了するための適切なCLIコマンドを選択してください。

*A: --projection-expression*

***
note:

* KVSのDynamo DB デフォルトで全ての属性を取って来ちゃうのである特定の属性のみを取り出すには--projection-expression
* 使用例は
```
aws dynamodb get-item \
--table-name ProductCatalog \
--key '{"Id":{"N":"123"}}' \
--projection-expression "Safety.Warning"
```

## 質問12
>あなたはソリューションアーキテクトとして、MongoDB Atlasに接続するLambda関数を構築しました。これは、一般的なデータベースのサービスプラットフォームであり、サードパーティAPIを使用して特定のデータを取得することもできます。 現在、あなたは「MongoDBデータベースのホスト名、ユーザー名、およびパスワードの環境変数」と、「Lambda関数で使用されるAPI資格情報」を作成する対応を行っています。その際にチーム外の開発者がプレーンテキストで環境変数を参照できないようにするために、最大限のセキュリティを確保することをユーザー側から求められました。

>このセキュリティ要件を満たす設定方法を選択してください。

*A: AWS KMSを新しく利用して、伝送中の暗号化のためのヘルパーを有効化する*

***
note:

* Lambdaで環境変数を使用するにはAWS KMSを使用して環境変数を暗号化する
* それをLambdaで利用するように設定すると復号化されて使える

設定方法

>・AWS Lambdaの環境変数のセクションで、[暗号化の設定]を展開します。

>・「伝送中に暗号化するKMSキー」と「保管時に暗号化するKMSキー」に先ほど作成したKMSキーを選択します。「伝送中の暗号化のためのヘルパーの有効化」にチェックを入れると環境変数の横に[暗号化]、[コード]のボタンが現れます

## 質問13
>A社はAWS LambdaとAPI GatewayおよびDynamoDBで構成したサーバーレスアーキテクチャを利用しています。Lambda関数は顧客ファイルを処理しており、多くの中間ファイルを作成しています。したがって、実行完了後に破棄されるLambda関数の一時ファイルを保存する必要があります。

>次の中で最適なLambda関数の一時ファイルの保存場所を選択してください。

*A: ローカルディレクトリの/tmpを利用する*

***
note:

* Lambdaで一時的なファイルを保存できる場所は/tmp
* 容量は最大512MB

## 質問14
>あなたはオークションアプリケーションを構築しています。データ保存とアクセスにDynamoDBを使用して、可用性の高いWebアプリケーションとする必要があります。オークションアプリケーションのDynamoDBには入札情報を保存しますが、入札は一時的な処理であるため、コスト効率の観点からもオークション実行後にDynamoDBテーブルデータを自動的に失効させたいと考えています。

>この要件を達成するDynamoDBテーブルの設定方法はどれでしょうか？

*A: TTL*

***
note:

* TTL【 Time To Live 】 生存時間
* TTLをDynamoDBで有効にすると特定のテーブルの項目に有効期限を設定できる
* TTLはテーブルの項目ごとにタイムスタンプで設定でき、契約または規制上の義務に従って特定の期間のみ保持する必要がある重要なデータがある場合、TTL を使用することで予定に沿ってデータを削除することができる

## 質問15

>あなたはAWSを得意としたアプリケーション開発エンジニアです。現在、ECSコンテナーを利用したアプリケーションを運用していますが、不具合の確認にはX-Rayを利用することが必要です。X-RayデーモンがECSで正しく検出されるように設定が必要です。

>この要件を達成するためのAWS X-Ray SDKの環境変数はどれでしょうか？

*A: AWS_XRAY_DAEMON_ADDRESS*

***
note:

* X-RayはLambdaのモニタリングのサービス
* X-Rayでログを取るにはデーモンを起動する必要があり、Lambdaのリソースが自動的に使われる
* AWS X-Ray SDKにおいてAWS_XRAY_DAEMON_ADDRESS 環境変数を設定することが必要

>Amazon ECS で、X-Ray デーモンを実行するためには、 実行用のDocker イメージを作成し、それを Docker イメージリポジトリにアップロードして、Amazon ECS クラスターにデプロイできます。タスク定義ファイルでポートマッピングとネットワークモード設定を使用すると、アプリケーションがデーモンコンテナと通信できるようになります。 このためには、 ポートマッピング、リンク、および AWS_XRAY_DAEMON_ADDRESS 環境変数でホストポートを省略する設定が求められます。

## 質問16
>あなたはAWS専門のエンジニアとして、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリを構築しています。データセットは、1日おきにデータを処理し、結果をS3に保存するように設定されたコンシューマー機能を持つAmazon Kinesis Data Streamによってリアルタイムで収集されます。しかしながら、S3バケットに収集されたデータはAmazon Kinesis Data Streamデータに対して明らかに不足しています。検証したところIoTセンサーには問題はなく、正しく Amazon Kinesis Data Streamsにデータが送付されています。

>この問題の最も可能性の高い原因を選択してください。

*A: Amazon Kinesis Data Streamsのデフォルトのデータ保持期限を超過した* 

***
note:

* Kinesis Data Streamsのデフォルトのデータ保存期間は24時間、最長で7日間のため長期間保存するのは向いてない
* 一日置きにデータを取得するようになっているが、24時間のため前日のデータはなくなっている

> Amazon Kinesis Data Streams では、ストリームのデータレコードの保持期間の変更をサポートしています。Kinesis data stream はデータレコードの順序付けられたシーケンスで、リアルタイムで書き込みと読み取りができることが前提となっています。したがって、データレコードはシャードに一時的に保存されます。レコードが追加されてからアクセスできなくなるまでの期間は、保持期間と呼ばれます。デフォルトで Kinesis data stream は 24 時間レコードを保持し、最大値は 168 時間です。 

## 質問17
> あなたはアプリケーションエンジニアとして、DynamoDBテーブルから個々のアイテムを読み取り、EC2インスタンスで変更処理をするアプリケーションを構築しています。 このアプリケーションでは、1つのプロセスにおいてデータエントリが100~500程度発生しており、プロセス完了までに時間がかかるようです。マネージャーから必要な時間を短縮するように依頼されました。

> どのような設定方式で短縮することが可能ですか？

*A: DynamoDBのBatchGetItemAPIを利用する。* 

***
note:

* BatchGetItemAPIでDynamoDBから大量レコードを並列に取得できる
* 最大100アイテム (ただし、16MBを超えないアイテム数) を並列で取得してくれる DynamoDB 側で並列処理をしてくれる

> BatchGetItem オペレーションは、プライマリキーを使用して複数のテーブルから複数の項目の属性を返します。1 回のオペレーションで取り出すことができる項目の最大数は 100 です。また、取り出される項目の数は、1 MB のサイズ制限を受けます。レスポンスサイズの制限を超えた場合、またはテーブルのプロビジョニングされたスループットの超過や内部処理エラーが原因で一部の結果しか返されなかった場合はDynamoDB は UnprocessedKeys 値を返します。その際、オペレーションをやり直して次の項目から取得を再開することができます。

## 質問18
> あなたはエンジニアとして、画像共有システムを開発しています。このアプリケーションはユーザーが共有したい画像をS3にアップロードして共有します。ユーザーがS3バケットおよび他のAWSリソースにファイルをアップロードする度に、アクセス許可が設定された一時認証を利用した処理処理を実行します。

> この処理に必要なAPIコールを使用する必要がありますか？

*A: AssumeRole*

***
note:

* AssumeRoleを活用すると、本来持っていない権限を一時的に得られるため、「デプロイ時のみ特定の権限を得る」ことができる
* IAMユーザ自身には、AssumeRoleができる権限しか持たせない
* デプロイ用のIAMロールにAssumeRoleして、一時的なアクセスキーを入手する
* 一時的なアクセスキーを用いて、S3にデプロイする
* デプロイ時にS3が用いるIAMロールを指定する

>一時的なセキュリティ認証情報をリクエストするには、AWS API で AWS Security Token Serviceを使用できます。これには、AWS リソースへのアクセスを制御できる一時的セキュリティ認証情報を持つ、信頼されたユーザーを作成および提供するオペレーションが含まれます。 一時認証情報を引き受けるためにアプリケーションはAWS STS AssumeRole APIオペレーションを呼び出し、使用するロールのARNを渡します。この操作によって一時的な資格情報で新しいセッションが作成されます。

## 質問19
> A社では、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリを構築しています。Amazon Kinesis Data Streamの開発担当者は、データフローのシャード数を調整して、データフローの転送速度の変化に適用させる対応を行っています。

> Amazon Kinesis Data Streamsのデータフローに応じた調整方法を選択してください。（2つ選択してください。）

*A: データフローの増加に対してシャードを分割する、データフローの減少に対してシャードをマージする*

***
note:

* Kinesis Data Streamsにオートスケーリング機能はありません。
* ただし、AWS Application Auto Scaling を利用して、Amazon Kinesis Data Stream に対してシャードを自動的に追加・削除するスケーリングポリシーを定義できる

## 質問20
> 開発者は非同期に呼び出されるLambda関数を使用するモバイルアプリケーションを開発しています。アプリケーションは、SQSキューによるポーリングをLambda関数が受け取って処理する方式であり、処理要求は2回再試行されるように設定しています。再試行に失敗した場合には失敗要因を分析するように失敗イベントを蓄積することが必要です。

> この要件を満たすために、利用するべき機能を選択してください。

*A: Lambdaデッドレターキュー*

***
note:

* デッドレターキューを使うとSQSで発行したキューでエラーになっているものを、自動的に別のキューや別の通知システムなどに連携することができる
* これをしないとエラーになったキューがずっとSQSに残り続けることになる

## 質問21
> あなたはソリューションアーキテクトとして、データアクセスにDynamoDBを使用して、可用性の高いWebアプリケーションを開発しています。 その際にインデックスを設定する必要がありますが、主キーと属性とを組合わせて複合キーを利用したいと考えています。

> データベースを作成するときに主キーを構成できる属性の最大数はいくつですか？

*A: 2*

***
note:

* DynamoDB のキーは三種類
* パーティションキー
  データをどのパーティションに配置するか決定する。
  各パーティションへのアクセスがなるべく均一になるようパーティションキーを設計すると良い。
* ソートキー
  ソートキーによってデータはパーティション内で並べ替えられて物理的に近くなるように配置される。
  QueryAPIではソートキーを指定して取り出すデータの範囲をフィルタできる。
  ソートキーの設定は任意。
* プライマリキー
 「パーティションキー」または「パーティションキーとソートキーの複合キー」のこと。
  プライマリキーによってデータは一意に識別される。
* DynamoDB は 2 種類の異なるプライマリキーを使う

## 質問23
> あなたはAPIコールでDynamoDBテーブルからデータを取得するサーバレスアーキテクチャを実装しています。このアプリケーションはLambdaプロキシ統合を使用してAPIゲートウェイと連携していますが、APIコールの応答とLambdaファンクションの実行状況をモニタリングする設定が必要です。

> このモニタリング要件を達成するCloudWatchの設定方法を選択してください。（2つ選択してください。）

*A: Latencyメトリックスを監視して、API呼び出しの全体的な応答性をみる、*<br >
*IntegrationLatencyメトリックスを監視して、バックエンドの応答性を測定する*

***
note:

* Amazon API Gateway はCloudWatch にメトリクスデータを毎分送信
* AWS/ApiGatewayの名前空間で保存される

メトリクス一覧
>* 4XXError：指定された期間に取得されたクライアント側エラーの数。
>* 5XXError：指定された期間に取得されたサーバー側エラーの数。
>* CacheHitCount：指定された期間内に API キャッシュから配信されたリクエストの数。
>* CacheMissCoun：API キャッシュが有効になっている特定の期間における、バックエンドから提供されたリクエストの数。
>* Count：指定された期間内の API リクエストの合計数。
>* IntegrationLatency：API Gateway がバックエンドにリクエストを中継してから、レスポンスを受け取るまでの時間。(中継してからのバックエンドの応答)
>* Latency：API Gateway がクライアントからリクエストを受け取ってから、クライアントにレスポンスを返すまでの時間。(バックエンドからクライアントまで全体の応答)

## 質問24
> A社は顧客管理向けのJavaアプリケーションをAWS上に構築しています。EC2インスタンスを利用してWEBサーバーを設置し、データベースシステムにはRDSを使用して顧客データを蓄積します。個人情報などの機密性の高いデータがやり取りされるため、KMSを利用して暗号化に使用するデータキーの暗号化されたコピーのみを返すAPI設定をアプリケーションに設定することになりました。暗号化処理では、Decrypt APIを呼び出してデータキーを復号化し、返されたプレーンテキストデータキーを使用して最終的にデータを暗号化します。

> 返されたプレーンテキストデータキーを使用して、最終的にデータを暗号化するために利用するべきKMS APIを選択してください。

*A: GenerateDataKeyWithoutPlainText*

***
note:

* 返答されたプレーンテキストデータキーを使用して最終的にデータを暗号化するためにはGenerateDataKeyWithoutPlaintextを利用
* データキー自体を作成するAPI
* DecryptやEncryptはその手段
* データキーの暗号化されたコピーのみを返すことを除いて、GenerateDataKeyと同じ処理

## 質問25
> ある企業は、WEBアプリケーションを運用するためにFargate起動タイプを使用するAmazon ECSクラスターを利用しています。 社内のセキュリティポリシーに準拠するために、データベース資格情報は環境変数を使用して提供される必要があります。 あなたはソリューションアーキテクトとして、認証情報が安全であること、およびクラスタ自体に平文で表示されないことを確認する必要があります。

> 次の方法の中で、最小の努力で実行することができる解決策を選択してください。

*A: AWS Systems Managerパラメータストアを利用して、データベースの設定データと機密データを保存し、KMSを利用して暗号化する。次にIAMロールをECSに設定してAWS Systems ManagerパラメータストアとKMSへのアクセス権限を付与する*

***
note:

* AWS Systems Manager パラメータストアは､設定データ管理と機密管理のための安全な階層型ストレージ
* Amazon ECSを使用すると、機密データをAWS Secrets ManagerまたはAWS Systems Managerパラメータストアに保存してから、そのコンテナ定義を参照することで、機密データをコンテナに注入することができる
* AWS Secrets ManagerとAWS Systems Managerパラメータストアの違いはよりセキュリティが高い
>Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
<br>SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。

## 質問27
>B社ではWEBアプリケーションのデータベースとしてRDS MySQLを利用しています。本日、このMySQLデータベースが応答しなくなる障害が発生し、あなたは対応に追われています。障害要因の解析のためには、障害の原因となったSQLステートメントのログ情報を確認することが必要です。

>この原因特定のために収集すべきログ取得方法はどれでしょうか。

*A: RDSのスロークエリログを有効にする*

***
note:

* MySQLではエラーログ、スロークエリログ、一般ログの三種類のログをモニタリングできる
* エラーログはデフォルトで生成され、実行に時間がかかったすべてのSQLステートメント内容を収集することができるのはスロークエリログ
* スロークエリログは、実行にlong_query_time秒以上かかるSQLステートメントで構成され、少なくともmin_examined_row_limit行を調べることで確認することができる
>■一般ログ：
mysqld の実行内容の一般的な記録です。サーバーは、クライアントが接続または接続解除したときに情報をこのログに書き込み、クライアントから受け取った各 SQL ステートメントをログに記録します。一般クエリーログは、クライアント側でエラーが疑われるとき、クライアントが mysqld に送信した内容を正確に知りたい場合に非常に役立つことがあります。

>■エラーログ
エラーログには mysqld が開始および停止された時期を示す情報と、サーバーが実行中に発生したあらゆるクリティカルエラーが格納されます。自動的にチェックまたは修復することが必要なテーブルが mysqld で検出された場合、エラーログに警告メッセージが書き込まれます。

>■スロークエリログ
スロークエリーログは、実行に要した時間が long_query_time 秒を超え、少なくとも min_examined_row_limit 行を検査する必要があった SQL ステートメントで構成されます。long_query_time の最小値およびデフォルト値は、それぞれ 0 および 10 です。値はマイクロ秒の精度まで指定できます。ファイルへのロギングの場合、時間はマイクロ秒の部分も含めて書き込まれます。テーブルへのロギングの場合、時間の整数部のみ書き込まれ、マイクロ秒の部分は無視されます。

## 質問28
>ある会社はSQSキューをLambdaが受け取って処理するサーバーレスアプリケーションによって、既存アプリケーションサーバーの業務処理を効率化しています。このLambda関数処理では、1分に1000リクエストが受信され、１つのリクエストを完了するのに100秒かかる高負荷な処理が予測されています。

>この高負荷処理を問題なく実行するための対策を選択してください。

*A: 上限値の制限オーバーに対してAWSに許可申請を行う*

***
note:

* デフォルトではLambdaは同一アカウントの同一リージョンで行える同時実行数の上限は1000
* 制限はリージョンごとに適用され、申請によって引き上げることができる
> Lambdaの同時実行数の計測は以下のように考えます。
> <br> 同時実行=（1秒あたりの呼び出し数）x（平均実行時間（秒）） 
<br>たとえば、 Lambda関数が平均10秒かかり、1秒あたり100個のイベントを発行するとします。次に、Lambda関数を1000同時に実行するため制限ぎりぎりとなります。今回のケースでは1分に1000リクエストが受信され、１つのリクエストを完了するのに100秒かかる高負荷が予測されており、1000の同時実行数を超える可能性が高いです。よって、AWSへのリクエストが必要となります。したがって、オプション2が正解となります。

## 質問29
>開発者はLambda関数とDynamoDBを連携させたモバイルアプリケーションを開発しています。このアプリケーションは、 DynamoDBテーブルへの新しいエントリを検出すると、Lambda関数によってエントリーされたデータを検証する検証プロセスを連携することが必要です。

>この要件を満たす最適で効率的なソリューション方式を選択してください。（2つ選択してください。）

*A: DynamoDBにSQSを設定して、データの新しい書き込み処理をトリガーにしてLambdaにメッセージを通知する*<br >
*AWS Lambda関数にDynamoDBストリームのARNを関連づける*

***
note:

* DynamoDBストリームはDynamoDBに加えられた変更を24時間保存するサービス
* DynamoDBストリームはDynamoDBに対する項目の追加、変更、削除をイベントとして検出できる
* Amazon DynamoDB は AWS Lambda と統合されているため、これを利用してDynamoDB テーブル内のデータ変更に対応するアプリケーションを構築する
> DynamoDB ストリーム を有効にした場合、書き込む AWS Lambda 関数にストリームの Amazon リソースネーム (ARN) を関連付ける設定を行います。これによって、テーブルの項目が変更されるとすぐに、新しいレコードがテーブルのストリームに表示されます。AWS Lambda はストリームをポーリングし、新しいストリームレコードを検出すると、Lambda 関数を同期的に呼び出すことができます。

## 質問30
>B社はAPI Gatewayを利用してLambdaを呼び出すサーバレスアプリケーションを構築しました。あなたはエンジニアとして、Lambda関数コードを圧縮して、Amazon S3にアップロードしてデプロイに向けて準備をしています。デプロイ手順をAWS上でなるべく自動化することが求められています。

>AWS SAMを利用したデプロイの自動化のために、選択すべきコマンドはどれでしょうか？ （2つ選択してください。）

*A: sam package ,sam deploy*

***
note:

* AWS SAMはLambda関数をローカルで実行しテストおよびデバッグができるフレームワーク
* ローカルで開発してSAMを利用してデプロイもできる
> AWS SAMは、AWS でサーバーレスアプリケーションを構築するために使用することができるオープンソースフレームワークです。AWS SAMはサーバーレスアプリケーションを定義するために使用する AWS SAM テンプレート仕様と、サーバーレスアプリケーションの構築、テスト、デプロイに使用する AWS SAM CLIで構成されています。 AWS SAMを利用してサーバーレスアプリケーションをローカルで開発およびテストした後、sam packageおよびsam deployコマンドを使用してアプリケーションのデプロイ方式を設定することができます。

## 質問33
>あなたはAWSでNode.jsアプリケーションを開発しています。現在はDynamoDBテーブルで読み込みキャパシティと書き込みキャパシティの設計を実施しているところです。以下の要件の設定が必要です。<br>
>・1秒間に30回の書き込み<br>
>・1秒間に20回の結果整合性のある読取処理<br>
>・両方の操作ですべてのアイテムのサイズが1KB<br>

>テーブルにプロビジョニングする必要がある最適な読み込みキャパシティーユニット（RCU）と書き込みキャパシティーユニット（WCU）の設定を選択してください。

*A: 10RCUと30WCU*

***
note:

* RCUは読み込みのキャパシティ 結果整合性の場合　1RCUあたり1秒間に4KBを2回　つまり8KB
* 強力な整合性の場合その1/2しか読み込めない
* 例えば10KBの項目を読み込んだら12KBに切り上げられ1.5RCU分消費される
* 1秒間に20回　結果整合性の場合2回のため10ユニットあればオッケー

* WCUは書き込みのキャパシティ 1WCUあたり1KBまでの1項目を書き込める
* 1KB以上の場合は1KBごとに切り上げてキャパを使うので1.5KBの場合は2WCU使う
* 1秒間に30回の書き込み × 1KB = 30WCU

```
■読み込みキャパシティーユニット（RCU）の計算方法

1 つの読み込みキャパシティーユニットは、最大サイズ 4 KB の項目について、1 秒あたり 1 回の強力な整合性のある読み込み、あるいは 1 秒あたり 2 回の結果整合性のある読み込みを表します。 例えば、10 ユニットのプロビジョニングされた読み取りキャパシティーでテーブルを作成するとします。これにより、最大 4 KB の項目について、1 秒あたり 10 回の強い整合性のある読み込み、または 20 回の結果的に整合性のある読み込みを行えます。 

4 KB を超える項目の読み込みには、より多くの読み取りキャパシティーユニットを消費します。たとえば、8 KB (4 KB × 2) の項目の強い整合性のある読み込みは、2 ユニットの読み込みキャパシティーユニットを消費します。同じ項目の結果的に整合性のある読み込みは、読み込みキャパシティーを 1 ユニットしか消費しません。 

したがって、RCUは10 ユニットのプロビジョニングされた読み取りキャパシティーでテーブルに対して、 20 回の結果的に整合性のある読み込みを行えるため、10RCUが正しい設定となります。 



■書き込みキャパシティーユニット（WCU）の計算方法

1 つの書き込みキャパシティーユニットは、最大サイズが 1 KB の項目について、1 秒あたり 1 回の書き込みを表します。

例えば、10 ユニットのプロビジョニングされた書き込みキャパシティーでテーブルを作成するとします。これにより、1 秒あたり最大でサイズが 1 KB の項目について、1 秒あたり 10 回の書き込みを行えます。

書き込みの項目サイズは、次の 1 KB の倍数に切り上げられます。たとえば、500 バイトの項目の書き込みは、1 KB の項目の書き込みと同じスループットを消費します。 

したがって、WCUは30 ユニットのプロビジョニングされた読み取りキャパシティーのテーブルに対して、 1 秒あたり最大でサイズ1 KB の項目について、1 秒あたり 30 回の書き込みを行えます。
```

## 質問34
> あなたはCI/CD環境を利用した開発を行っているエンジニアです。AWS CLIを使用してAWS CodeBuildによりプロジェクトをビルドする必要があります。 pintorapi.ymlファイルを設定してビルドコマンドを実行する設定を実施していますが、その際にビルド出力アーティファクトを暗号化する必要があります。

> ビルド出力アーティファクトを暗号化する設定方法を選択してください。

*A: 使用するカスタマーマスターキーを指定する*

***
note:
>AWS KMS カスタマーマスタキー (CMK) にアクセスする必要があります。デフォルトでは、CodeBuild はAmazon S3 の AWS Managed CMK を使用します。 この CMK を使用しない場合はユーザー自身で管理する CMK を作成して設定する必要があります。

## 質問35
>A社のシステム開発プロジェクトではソフトウェア配信プロセスを改善するために CI / CD環境を使用して、すべてのアプリケーションを構築し、Dockerコンテナとしてパッケージ化してデプロイすることを決定しました。 AWS CodePipelineとAWS CodeBuildによってプロジェクトのパイプラインが実行されると、Dockerイメージが保存されたECRにアクセスしてイメージをプッシュする処理が走ります。あなたがパイプラインを実行したところ認証エラーが発生したようです。

>このエラーの原因として最も可能性の高い問題を選択してください。

*A: CodeBuildサービスのIAMアクセス許可が間違っている*

***
note:
>IAMを利用した認証アクセスに失敗しています。AWS CodeBuildを利用してECRと連携させるためにはIAMによるECRに対するアクセス許可をCodeBuild側に設定する必要があります。

> CodeBuildを利用してDocker イメージを Amazon ECR リポジトリにプッシュするにはイメージのプッシュ先となる Amazon ECR レジストリに対して Docker クライアントを認証することが必要です。

## 質問36
>A社はAWSのサーバレスアーキテクチャを推進しており、AWS Lambda、API Gateway、およびDynamoDBを単一のスタックで構成した新しいサーバーレスアーキテクチャを実装することになりました。あなたが担当しているLambda関数は重いワークロード処理に利用されており、リリースしたところパフォーマンスが思わしくありません。

>コードを変更せずにLambda関数のパフォーマンスを改善するにはどうすればよいですか？

*A: Lambda関数に割り当てられたメモリを増加させる*

***
note:

* Lambda関数のパフォーマンスをあげるにはメモリを増加させること

>Lambdaでは関数の実行時に使用できるメモリ量は 128 MB ～ 3,008 MB の範囲 (64 MB 単位) で選択することができます。  AWS Lambdaは、M3タイプなどの汎用Amazon EC2インスタンスタイプと同じ比率を使用して、CPU パワーが直線的に割り当てられます。1,792 MB では、関数は 1 つのフル vCPU (1 秒あたりのクレジットの 1 vCPU 秒) に相当します。 

## 質問37
>現在、A社ではAmazon ECSを利用したDockerによるアプリケーション開発を実施しています。あなたはエンジニアとして、Dockerコンテナを実行する上でのタスク定義の設定を担当しています。タスクのエージェント構成において、ECSにIAMロールを許可するための設定が必要です。

>どのような設定を行う必要がありますか？

*A: ECS_ENABLE_TASK_IAM_ROLE=Trueに設定する*

***
note:

* ECSにIAMロールを許可するにはECS_ENABLE_TASK_IAM_ROLE=Trueにする必要がある

>Amazon ECS コンテナエージェントでは、多数の設定オプションがサポートされており、ほとんどの設定は環境変数を通じて設定する必要があります。コンテナインスタンスが Amazon ECS-optimized AMI の Linux バリアントを使用して起動された場合は、これらの環境変数を /etc/ecs/ecs.config ファイルに設定してからエージェントを再び開始できます。起動時に Amazon EC2 ユーザーデータを使用して、コンテナインスタンスにこれらの設定変数を作成することもできます。 

## 質問38
>あなたの会社はCloudFormationテンプレートを利用してリソースをセットアップしています。テンプレートは、Stack1、Stack2、およびStack3で構成されています。 Stack1は、Stack2およびStack3で参照されるWebアプリケーションのVPC、セキュリティグループ、およびサブネットをプロビジョニングしています。 また、Stack2はStack3のセキュリティグループも利用しています。全てのスタックを実行した後、それらを全て削除することにしました。

>スタックを削除するためには、どのスタックから削除を実行する必要がありますか？

*A: スタック2を削除した後にスタック３を削除し、最後にスタック１を削除する*

***
note:

* スタック2とスタック３はスタック１を参照しているため、スタック１は最後　
* スタック2はスタック３のリソースを参照しているため、スタック２が削除されないとスタック３は削除できない

## 質問39
>A社はAWSを利用してNode.jsアプリケーションを構築し、Elastic Beanstalkを利用して展開しています。アプリケーションは1秒間に300リクエストを処理し、結果はDynamoDBテーブルに保存されます。あなたはトラブルシューティングにAWS X-Rayを設定するようにマネージャーから依頼されました。リザーバーが使い果たされた後に一致するリクエストの割合でX-Rayのサンプリングを実施すること、及び1秒あたり合計260のリクエストをサンプリングするように割り当てることが必要です。

>上記の要件を満たすために、適切なX-Rayのサンプリングルールの設定方式を選択してください

*A: サンプリングルール構成でリザーバサイズを250に、固定レートを30%にする*

***
note:

>＜1秒あたりのサンプリングされた要求の合計を計算するには、次の式を使用できます。＞<br>
>サンプリングリクエスト数　＝　リザーバーサイズ＋（（1秒あたりの着信リクエスト-リザーバーサイズ）*固定レート）   
>300の着信リクエストから毎秒合計260のリクエストをサンプリングする場合、リザーバサイズを250に、固定レートを20％に設定してから、上記の式を使用して答えを確認します。 <br>
>= 250 +（（300-250）* 20％）<br>
>= 260リクエスト 

## 質問40
>B社ではLambda関数とS3を連携させたアプリケーションをLambda関数１とLambda関数２を利用しています。このLambda関数ではユーザーがデータを更新するとDynamoDBテーブルを更新して、過去データはS3に保存します。 ALBを使用して、着信トラフィックを登録済みターゲットとする2つのLambda関数に分散します。しかしながら、この分散が機能せず、ピーク時に次のように処理パフォーマンスが不均衡になる問題が発生しています。結果として、Lambda関数２のみパフォーマンスが低下してしまいます。

>この問題の最も可能性の高い根本原因は次のうちどれですか？

*A: Lambda関数1に提供される同時実行制限がLambda関数2よりも大幅に高い*

***
note:

>初めてLambda関数を呼び出すと、AWS Lambda によてLambda関数のインスタンスが作成され、イベントを処理するためのハンドラーメソッドが実行されます。関数がレスポンスを返すと、追加イベントを処理するために作業を継続します。最初のイベントの処理中に関数を再び呼び出すと、Lambda により別のインスタンスが作成されます。 さらにイベントが入ってくると、Lambda は使用可能なインスタンスにそれらを送信し、必要に応じて新しいインスタンスを作成します。

>関数の同時実行数とは同時にリクエストを処理するインスタンス数を指します。最初のトラフィックバーストの場合、関数の同時実行数は最初のレベル (500 から 3000 の間 ) に達する可能性があり、これはリージョンによって異なります。 東京リージョンの同時実行制限は1000で、すべてのLambda関数で共有されます。

>このようにLambda関数は実行に対して、都度インスタンスをプロビジョニングして処理を進めることになります。したがって、複数のLambda関数で処理を分散させている場合にプロビジョニング数が少なく同時実行できる数が少ないと、Lambda関数2は着信リクエストを調整してパフォーマンスが低下してしまう可能性があります。

* 要はプロビジョニングがLambda2の方が多いのにそれに対して実行する処理が少ないからそれに合わせてパーフォマンスが下がったということ

## 質問42
>A社ではAmazon ECSクラスターを利用したマイクロサービスアーキテクチャのアプリケーションを構築しています。 Amazon ECSではタスク設定おいて、タスク配置戦略を定義する必要があります。このタスク配置戦略によって、使用中のインスタンスの数を最小限に抑えてコスト効率を向上させる必要があります。

>要件に合致したタスク配置戦略を選択してください。

*A: binpackタスク配置戦略を使用する*

***
note:

* Binpack CPU またはメモリの最小利用可能量に基づいてタスクを配置。使用するインスタンス数を最小限に抑える配置戦略

* Random タスクをランダムに配置

* Spread
指定された値に基づいてタスクを均等に配置 有効な値は instanceId (または同じ効果を持つ host)、または attribute:ecs.availability-zone などのコンテナインスタンスに適用される任意のプラットフォームまたはカスタム属性<br>
サービスタスクはそのサービスからのタスクに基づいて分散されます。スタンドアロンタスクは、同じタスクグループからのタスクに基づいて分散

## 質問45
>B社ではAWS Organizationsを使用して、さまざまな部門で使用されている複数のAWSアカウントを管理しています。現在、開発部門ではアプリケーションAとアプリケーションB用の２つのAWSアカウントを利用しています。アプリケーションAの新バージョンでは、アプリケーションBの環境への接続が必要です。そのため、アプリケーションAアカウントのメンバーに対して、アプリケーションB環境へのアクセス許可が必要となります。

>アプリケーションAアカウントに対する必要なアクセス許可の設定方法を選択してください。

*A: アプリケーションAアカウントのメンバーに対して、アプリケーションB環境のリソースへのクロスアカウントアクセスを許可する*

***
note:

> IAM ユーザーには、AWS アカウント内のロール、または所有する他の AWS アカウントで定義されたロールに切り替えるアクセス許可を付与することができます。このようなアクセス許可をクロスアカウントアクセスと呼びます。

## 質問46
>B社にはEC2インスタンスベースのWEBアプリケーションをElastic Beanstalkを利用して展開しています。あなたはエンジニアとして、WebアプリケーションをAPI Gatewayと統合する対応を依頼されました。API Gatewayはクライアントが送信したメソッドリクエストをバックエンドに渡します。メソッド確立後はクライアントとバックエンドがHTTPエンドポイントにより直接対話します。

>この要件を満たす、最適なAPI Gateway統合タイプを選択してください

*A: HTTP_PROXY*

***
note:

```
■AWS: このタイプの統合では、API は AWS のサービスアクションを公開します。AWS 統合では、統合リクエストと統合レスポンスの両方を設定し、メソッドリクエストから統合リクエストへの、また統合レスポンスからメソッドレスポンスへの、データマッピングを設定する必要があります。   

■AWS_PROXY: このタイプの統合では、さまざまな用途に柔軟に利用できる合理化された統合設定があり、API メソッドを Lambda 関数呼び出しアクションと統合できます。この統合は、クライアントと統合 Lambda 関数との間の直接的なやり取りに依存します。このタイプの統合は、Lambda プロキシ統合とも呼ばれ、ユーザーが統合リクエストまたは統合レスポンスを設定することはありません。API Gateway は、クライアントから受け取ったリクエストをバックエンドの Lambda 関数への入力として渡します。統合 Lambda 関数は、この形式の入力を受け取り、使用可能なすべてのソースからの入力 (リクエストヘッダー、URL パス変数、クエリ文字列パラメータ、該当する本文など) を解析します。その後、こちらの出力形式に従って結果を返します。これは、API Gateway を介した Lambda 関数呼び出しに適した統合タイプであり、関数呼び出しアクション以外の AWS アクションなど、他の Lambda のサービスアクションには適用されません。 

■HTTP: このタイプの統合は、API がバックエンドの HTTP エンドポイントを公開することを可能にします。HTTP 統合 (HTTP カスタム統合とも呼ばれます) では、統合リクエストと統合レスポンスの両方を設定する必要があります。メソッドリクエストから統合リクエストへの、また統合レスポンスからメソッドレスポンスへの、データマッピングを設定する必要があります。   

■HTTP_PROXY: HTTP_PROXY統合では、クライアントは 1 つの API メソッドで合理化された統合設定を使用して、バックエンドの HTTP エンドポイントにアクセスできます。この場合、ユーザーが統合リクエストまたは統合レスポンスを設定することはありません。API Gateway は、クライアントから受け取ったリクエストを HTTP エンドポイントに渡し、HTTP エンドポイントから送り出されたレスポンスをクライアントに渡します。このようにHTTPエンドポイントを介して対話が行われるため、クライアントとバックエンドがAPI Gatewayの介入なしで直接対話することができます。

■MOCK: このタイプの統合では、API Gateway はリクエストをさらにバックエンドに送信することなく、レスポンスを返します。このタイプの統合は、API のテストに便利です。バックエンドの使用料金が発生することなく、統合設定のテストに使用したり、API の共同開発に使用したりできるためです。共同開発では、チームは MOCK 統合を使用して、他のチームが所有する API コンポーネントのシミュレーションを設定することで、自分たちの開発成果を区分することもできます。また、CORS 関連のヘッダーを返して、API メソッドが CORS へのアクセスを許可するようにもできます。実際に、API Gateway コンソールは Mock 統合で OPTIONS メソッドを統合して CORS をサポートします。ゲートウェイレスポンス は Mock 統合の他の例です。
```

## 質問47
>開発者はEC2インスタンスとDynamoDBを連携させたWEBアプリケーションを開発しています。このWEBアプリケーションのユーザー行動データはDynamoDBテーブルに蓄積される仕組されます。あなたはエンジニアとして、訪問者数を追跡して最適な広告を表示する機能を開発しています。

>最小構成で要件を満たすためのソリューションを選択してください。（2つ選択してください。）

*A: アトミックカンター、UpdateItemオペレーションを使用する*

***
note:

* アトミックカウンターは書き込みリクエストを妨害することなく、無条件で増分される数値属性
* アトミックカウンターではUpdateItem を呼び出すたびに数値が増加されて、カウントすることができる。そのため、同一ユーザーからのアクセスを複数回カウントする
* アトミックカウンターは厳密なカウントじゃないため二重計上の可能性あり

## 質問49
>あなたはAWS専門のエンジニアとして、車両データをリアルタイムに取得してAmazon Kinesis Data Streamsに送信するモバイルアプリケーションを構築しています。 KinesisのプロデューサーはPutRecord APIコールを使用して、ストリームにデータを送信していますが、処理に失敗すると同じデータを二回送信し、アプリケーションに不具合が発生してしまいました。不具合を確認したところ、データエントリが重複していることが原因のようです。

>この問題を解決するソリューションを選択してください。

*A: レコード内に主キーを埋め込む*

***
note:

* レコードが複数回 Amazon Kinesis Data Streamsアプリケーションに配信される理由は、主に「プロデューサー(送信側)の再試行」と「コンシューマー(受信側)の再試行」の 2 つ
* データストリーム内のエントリが誤って重複しないようにするためには、レコード内に主キーを埋め込み、後で処理する際に重複を削除する対応をする

## 質問50
>B社ではAWS SAMを使用して、サーバーレスアプリケーションを構築およびデプロイしています。あなたは SAMスクリプトおよびその他のサービス構成を含むCloudFormationテンプレートを利用して、このアプリケーションのインフラ構成を起動する準備を行っています。

>このタスクを達成するためのCloudFormationの設定方法を選択してください。

*A: TransfromセクションにてAWS SAMのバージョンを指定する*

***
note:

* サーバーレスアプリケーションのインフラ構成を起動するためには、CloudFormationテンプレートのAWS::Serverless Transformセクションにおいて、AWS SAMのバージョンを指定することが必要
* SAM = AWS Serverless Application Model

## 質問51
>あなたはNodeJSを使用してAWSでサーバーレスアプリケーションを構築しています。 アプリケーションは、AWS Lambda、API Gateway、およびDynamoDBを利用して単一のスタックで構成されており、 AWS上にコンピューティングリソースを展開する必要があります。

>NodeJSで構成されたサーバーレスアプリケーションを適切に展開する方法を選択してください。

*A: NodeJSのカスタムランタイムを含む新しいレイヤーを作成し、そのランタイムを使用するLambda関数を起動する*

***
note:

* Lambdaランタイムは、どのプログラミング言語でも実装できランタイムは関数が呼び出されたときに Lambda 関数のハンドラメソッドを実行するプログラム

```
Lambda関数によってNodeJSで構成されたサーバーレスアプリケーションを適切に展開するためには、NodeJSのカスタムランタイムを含む新しいレイヤーを作成し、そのランタイムを使用するLambda関数を起動することが必要です。AWS Lambda では、ランタイムの使用を通じて複数の言語がサポートされます。関数を作成するときにランタイムを選択し、関数の設定を更新してランタイムを変更することができます。基盤となる実行環境は、関数コードからアクセスすることができる追加のライブラリと環境変数を提供します。
```

## 質問52
>開発者はLambda関数とDynamoDBを連携させたモバイルアプリケーションを開発しています。 アーキテクチャは、クエリのパーティションキー値で指定されているように、テーブルの単一パーティションに対して複数のインデックスを利用したクエリを実行できるように設計する必要があります。

>このタスクを達成するための最適な設定方式を選択してください。

*A: テーブルが作成される前にローカルセカンダリインデックスを追加するn*

***
note:

* DynamoDBにおいて複雑で、プライマリーキー以外の検索が必要な場合は代替のソートキーを利用 
そのためには、テーブルが作成される前にローカルセカンダリインデックスを追加することが必要
* DynamoDBにおいては同じパーティション内の複数のアイテムは、基本的に暗黙のインデックスに従って整理されています。これに加えて、別の規則で整理インデックスを構築することが、これをローカルセカンダリーインデックスと呼びます。

## 質問53
>あなたはエンジニアとして、顧客プロファイル保存用のDynamoDBテーブルを作成しています。 顧客情報を検索するために、現在はテーブルのパーティションキーを設定していますが、ユーザからの要望として、非キー属性のクエリを高速化できるインデックスが必要となりました。

>非キー属性のクエリを高速化するために、開発者はどのタイプのインデックスをテーブルに追加する必要がありますか？

*A: グローバルセカンダリインデックス*

***
note:

```
グローバルセカンダリインデックス（GSI）というのは、テーブルに対して自由に追加できるインデックスです。GSIはハッシュキーテーブル及び複合キーテーブルどちらにでも設定可能です。アプリケーションによっては、さまざまな属性をクエリ基準に使用して、いろいろな種類のクエリを実行する必要があります。このような要件に対応するために、1 つ以上のグローバルセカンダリインデックスを作成して、Amazon DynamoDB でそのインデックスに対して Query リクエストを発行できます。これにより、クエリ処理を効率的に、高速に実行することができます。

ローカルセカンダリインデックスはアプリケーションにソートキーという選択肢を提供するために、Amazon DynamoDB テーブルに 1 つ以上のローカルセカンダリインデックスを作成して、それらのインデックスに対して Query または Scan リクエストを実行できます。これはパーティションキーとソートキーで構成されるため要件に合致していません。また、ローカルセカンダリインデックスはすべてのパーティションでテーブル全体に対してクエリを実行できるインデックスではありません。
```

## 質問57
>あなたはソリューションアーキテクトとして、新しい決済処理システムを構築しています。このアプリケーションでは分散セッション管理コンポーネントとしてRedis用のAmazon ElastiCacheを使用して、高速な処理を実現することが必須となっています。 現在、開発部門の多数のエンジニア達はElastiCacheクラスターにアクセスできるようになっていますが、Redisコマンドを実行する権限が付与される前に、パスワード入力を要求してポータル内のセッションデータを保護する必要があります。

>次のどの方式によってこの要件を満たすことができますか。

*A: 新しいRedisクラスターによって生成されたRedisAUTHを利用して認証する*

***
note:

* RedisはElastiCacheのエンジンのことでデータの永続化とレプリケーションが可能
* もう一種類はMemcached そっちはデータの永続化とレプリケーションができない
* Redis AUTH によるユーザーの認証を使うことでこの要件を満たすことができる　
Redis AUTH コマンドを使用して、パスワードで保護された Redis サーバー上の Redis コマンドの実行権限をユーザーに付与する前に、パスワードの入力を求めることでデータセキュリティを強化できる

## 質問58
> あなたはEC2インスタンスとAmazon SQSキューを連携させた大量のデータトラフィック処理を実行するアプリケーションを開発しています。これらのキューには1GBの大きなデータも含まれており、SQSのAWS制限となっているメッセージサイズ制限を超えてしまっています。

> この要件に対応するために必要なソリューションを選択してください。

*A: AmazonSQS拡張クライアントライブラリを利用する*

***
note:

* Amazon S3 および Java 用 Amazon SQS 拡張クライアントライブラリ を使用することで、SQSキューに送信されるメッセージサイズの制限を超える大きなサイズのメッセージを許可することができる
> これは特に、2 GB までのサイズのメッセージを保存および処理するのに役立ちます。アプリケーションで、キューを連続して作成して非アクティブな状態のままにするか、大量のデータをキューに保存する必要がない限り、データの保存に Amazon S3 を使用することが望ましいです。

```
Java 用 Amazon SQS 拡張クライアントライブラリ ライブラリは、以下の対応が可能です。

・メッセージを常に Amazon S3 に保存するか、メッセージのサイズが 256 KB を超える場合のみ保存するかを指定する。 
・Amazon S3 バケットに保存されている単一のメッセージオブジェクトを参照するメッセージを送信する。
・Amazon S3 バケットから該当するメッセージオブジェクトを取得する。
・Amazon S3 バケットから該当するメッセージオブジェクトを削除する。
```

## 質問60
>あなたはAWS CLIで作業する開発者です。現在Amazon CloudWatchを使用したEC2インスタンスの詳細モニタリングを有効化する設定を行っています。

>AWS CLIを利用したモニタリング設定コマンドはどれでしょうか？

*A: aws ec2 monitor-instances --instance-ids i-1111111111コマンド*

***
note:

* cloudwatchをCLI上で実行するにはaws ec2 monitor-instances --instance-ids i-11111111111コマンドと特定のEC２インスタンスIDを指定して実行する

## 質問61
>B社はAWSでサーバーレスアプリケーションを構築しています。 このアプリケーションはAWS Lambda、API Gateway、およびDynamoDBを利用して、単一のスタックで構成されています。このLambda関数は処理に失敗するとDead Letter Queueを使用して未処理のイベントを処理する設定を行っています。また、このLambda関数は2回再試行する設定です。

>Dead Letter Queueが利用されるケースはどれでしょうか？

*A: 非同期呼び出し処理の試みが3回とも失敗した場合*

***
note:

* Dead Letter Queueは非同期呼び出し処理の試みが 3 回 とも失敗した場合、Lambda は Amazon SQS キューまたは Amazon SNS トピックにイベントを送信する
* SQSのメッセージの保存期間は初期設定の場合４日で保持期間は最大１４日間まで設定することが可能

## 質問63
>B社ではサーバレスアプリケーションとしてAWS Lambda、API Gateway、およびDynamoDBで構成した新しいアプリケーションを実装しました。 最近になって、不正なドメインからのAPIアクセスが多発しており、APIコール処理のパフォーマンスに影響を与えています。

>この問題を改善するためにどの設定を利用しますか？

*A: Cross-origin resource sharingの制限*

***
note:

```
Cross-origin resource sharing (CORS) は、ブラウザで実行されているスクリプトから開始されるクロスオリジン HTTP リクエストを制限するブラウザのセキュリティ機能です。REST API のリソースが非シンプルクロスオリジンの HTTP リクエストを受け取る場合、CORS サポートを有効にする必要があります。

逆に、APIリソースがAPI自身のドメイン以外のドメインからリクエストを受信し、これらのリクエストのサービスを制限したい場合は、リソース上の選択されたメソッドのCross-origin resource sharing （CORS）を無効にする必要があります。今回のシナリオでは、API自身のドメイン以外のドメインからリクエストを制限したいため、CORSの制限を実施することが求められています。
```

* 自分自身のAPIのドメインからくるリクエストを制限するのがCross-origin resource sharing (CORS)

## 質問65
>あなたはソリューションアーキテクトとして、ロードバランサーを設置したAmazon ECSクラスターで実行されるDockerアプリケーションを構築しています。このアプリケーションではDynamoDBを頻繁に使用していますが、その性能を向上させる必要があります。あなたはワークロードを均等に分散し、プロビジョニングされたスループットを効率的に使用することでデータベースのパフォーマンスを向上させようと考えました。

>パフォーマンスを向上させるためにDynamoDBテーブルに設定するべき方法を選択してください。

*A: カーディナリティの高いパーティションキーを使用する*

***
note:

* カーディナリティ度が低いとは、カラムの値の種類がレコード数に比べて少ないこと 
* カーディナリティ度が高いとは、カラムの値の種類がレコード数に比べて多いことをあらわす 種類の絶対数の多少でなく度合いである
* レコードよりカラムの値の種類の方が多いとカーディナリティが高いってこと！
* 例えば性別とかのテーブルはレコードに対して男と女の2種類しかないためカーディナリティが低い
* インデックスはカーディナリティの高い(種類が多いor一意の値）列に作成すると効率がいい

```
DynamoDB は次の状況でテーブルに追加のパーティションを割り当てます。

■テーブルのプロビジョニングされたスループット設定を、既存のパーティションがサポートできる以上に増やす。

■既存のパーティションが容量いっぱいになり、より多くのストレージ領域が必要になる。

一般に、パーティションキー値の総数に対するアクセスされたパーティションキー値の比率が高いほど、プロビジョニングされたスループットをより効率的に使用します。その一例として、カーディナリティの高い属性を持つパーティションキーを使用することが挙げられます。これには、各項目に多数の異なる値があります。テーブルにカラムがあるとして、カラムに格納されているデータの種類がどのくらいあるのか(カラムの値の種類の絶対値)を、カーディナリティといい、「カラムのデータの種類が、テーブルのレコード数に比べて多い場合、 カーディナリティが高い」といいます。
```





