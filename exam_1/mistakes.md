## 質問3
>A社ではアプリケーション開発においてAWSのcodeシリーズと呼ばれるAWS CodeCommitとAWS CodeDeployなどを利用して開発・テスト・デプロイまでのパイプラインを利用したCI/CDを整備しています。CodeDeployによってデプロイを実行した際に、デプロイが成功したかどうかを担当者が確認することが必要です。

>この要件を達成するためにCodeDeployの設定において、実施すべき対応を選択してください。

*A: .appspecファイルをルートディレクトリに定義する*

***
note:

* .appspecファイルをルートディレクトリに定義することで、CodeCommitとCodeDeployの設定に対して、アプリケーションのデプロイ時にファイルへのアクセス許可を変更して、デプロイを制御することができるようになる
* CodeDeployの設定は.appspecファイル
* AppSpec は AWS CodeDeploy で実行するデプロイ処理の内容を設定するYAML ファイル


## 質問4

>あるベンチャー企業ではAWSを利用したCI/CD環境を構築しています。開発環境などはAmazon ECSを利用して全てDocker形式で展開できるようにしています。あなたは開発担当者として、コンテナの設定としてタスクの割り当てを別々に設定したいと考えております。コンテナーのタスク割り当てで資格情報を分割する方法が必要です。

>この設定のために、どのアクションを実行することが必要となりますか？

*A: ECSに対してIAMロールを作成してタスクに割り当てる*

***
note:

* Amazon ECSにおいてコンテナが別のタスクに属する別のコンテナの資格情報へのアクセスを制御するにはアクセス許可の設定が必要（各コンテナには各ロールが必要ってこと）
* ECSのコンテナエージェントはユーザーに代わってECS APIを実行するためにIAMロールが必要
* このIAMロールはタスク実行IAMロールという
* 複数のタスク実行ロールを、アカウントに関連付けることができECSのタスクを複数実行できるようになる

## 質問7

>あなたの会社では顧客データを保存するためにAmazon S3を利用しています。顧客データはセキュリティを強固にする必要があるため、アクセスログを有効にしてステータスについて確認できるような設定をしました。バケットのデータ増加は一週間で1GBほどですが、アクセスログをオン後にバケットのサイズが３日で10GB増加したようです。

>このデータ増加の原因として考えられる要因を説明してください。

*A: サーバーアクセスログはS3バケットを利用するだけでもアクセスログを増加させる*

***
note:

* サーバーアクセスログはストレージデータの増加がデメリット
* サーバーアクセスログはアクセスログのレコードごとに 1 つのアクセスリクエストの詳細として、リクエスタ、バケット名、リクエスト時刻、リクエストアクション、レスポンスのステータス、エラーコード (存在する場合) などの情報が取り込まれる。 ソースバケットとターゲットバケットが同じである場合、バケットに書き込まれるログに関する追加のログが作成される。これにより、利用が頻繁であればあるほどS3バケットにログデータが追加される
つまりソースとそれに対するアクセスログが自分自身の場合には2倍のアクセスログになるということ

## 質問9
>A社では社内の文書共有システムとしてS3をストレージに利用しています。社内の方針で個人PCに保存しているドキュメントを個人管理用のストレージエリアに保存することが決定されました。そのためには、AWSアカウントによって定義されたユーザー全てに、S3バケットに個人用の保存スペースを設定することが必要です。

>この個人用スペースをセットアップする最適な方法を選択してください。

***
note:

*A: 動的変数を使用してIAMポリシーを一つ作成し、全てのユーザーの属するIAMグループにアタッチする*

* 動的変数を使用してIAMポリシーを1つ作成し（一個のルール）、全てのユーザーの属するIAMグループにアタッチすること（全員にそれを反映）でS3バケットに個人用スペースをセットアップすることができる
* IAMポリシーのJSONに各ユーザーに適用できるような動的変数を使用したIAMポリシーを設定して、S3バケットにおいてS3バケット個人用スペースの読み取り、および書き込みの許可を与える

## 質問10
>あなたはAWS専門のエンジニアとして、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリケーションを構築しました。このアプリケーションは、EC2インスタンスでKCLベースでKinesisと連携しています。最近になって利用ユーザーが増加したことで、Kinesis Data Streamにおけるトラフィックが増加したため、あなたはシャードを分割して6シャードから10シャードに増強しました。

>シャードを処理するためにデプロイできるEC2インスタンスの最大数はいくつですか？

*A: 10*

***
note:

* Kinesisはシャードからなるストリームを作成してストリーミングデータを保持して処理する
* 1シャードにつき1EC2を割り当てられるため、10になる

## 質問11
>あなたはAWS専門のエンジニアとして、AWSリソースのセットアップを実施しています。あなたはアプリケーションCLIオプションの設定で、DynamoDBのアプリケーション上の読み込み設定を行っています。DynamoDBスキャンを実行し、特定の属性サブセットを取得する対応が必要です。

>この操作を完了するための適切なCLIコマンドを選択してください。

*A: --projection-expression*

***
note:

* KVSのDynamo DB デフォルトで全ての属性を取って来ちゃうのである特定の属性のみを取り出すには--projection-expression
* 使用例は
```
aws dynamodb get-item \
--table-name ProductCatalog \
--key '{"Id":{"N":"123"}}' \
--projection-expression "Safety.Warning"
```

## 質問12
>あなたはソリューションアーキテクトとして、MongoDB Atlasに接続するLambda関数を構築しました。これは、一般的なデータベースのサービスプラットフォームであり、サードパーティAPIを使用して特定のデータを取得することもできます。 現在、あなたは「MongoDBデータベースのホスト名、ユーザー名、およびパスワードの環境変数」と、「Lambda関数で使用されるAPI資格情報」を作成する対応を行っています。その際にチーム外の開発者がプレーンテキストで環境変数を参照できないようにするために、最大限のセキュリティを確保することをユーザー側から求められました。

>このセキュリティ要件を満たす設定方法を選択してください。

*A: AWS KMSを新しく利用して、伝送中の暗号化のためのヘルパーを有効化する*

***
note:

* Lambdaで環境変数を使用するにはAWS KMSを使用して環境変数を暗号化する
* それをLambdaで利用するように設定すると復号化されて使える

設定方法

>・AWS Lambdaの環境変数のセクションで、[暗号化の設定]を展開します。

>・「伝送中に暗号化するKMSキー」と「保管時に暗号化するKMSキー」に先ほど作成したKMSキーを選択します。「伝送中の暗号化のためのヘルパーの有効化」にチェックを入れると環境変数の横に[暗号化]、[コード]のボタンが現れます

## 質問13
>A社はAWS LambdaとAPI GatewayおよびDynamoDBで構成したサーバーレスアーキテクチャを利用しています。Lambda関数は顧客ファイルを処理しており、多くの中間ファイルを作成しています。したがって、実行完了後に破棄されるLambda関数の一時ファイルを保存する必要があります。

>次の中で最適なLambda関数の一時ファイルの保存場所を選択してください。

*A: ローカルディレクトリの/tmpを利用する*

***
note:

* Lambdaで一時的なファイルを保存できる場所は/tmp
* 容量は最大512MB

## 質問14
>あなたはオークションアプリケーションを構築しています。データ保存とアクセスにDynamoDBを使用して、可用性の高いWebアプリケーションとする必要があります。オークションアプリケーションのDynamoDBには入札情報を保存しますが、入札は一時的な処理であるため、コスト効率の観点からもオークション実行後にDynamoDBテーブルデータを自動的に失効させたいと考えています。

>この要件を達成するDynamoDBテーブルの設定方法はどれでしょうか？

*A: TTL*

***
note:

* TTL【 Time To Live 】 生存時間
* TTLをDynamoDBで有効にすると特定のテーブルの項目に有効期限を設定できる
* TTLはテーブルの項目ごとにタイムスタンプで設定でき、契約または規制上の義務に従って特定の期間のみ保持する必要がある重要なデータがある場合、TTL を使用することで予定に沿ってデータを削除することができる

## 質問15

>あなたはAWSを得意としたアプリケーション開発エンジニアです。現在、ECSコンテナーを利用したアプリケーションを運用していますが、不具合の確認にはX-Rayを利用することが必要です。X-RayデーモンがECSで正しく検出されるように設定が必要です。

>この要件を達成するためのAWS X-Ray SDKの環境変数はどれでしょうか？

*A: AWS_XRAY_DAEMON_ADDRESS*

***
note:

* X-RayはLambdaのモニタリングのサービス
* X-Rayでログを取るにはデーモンを起動する必要があり、Lambdaのリソースが自動的に使われる
* AWS X-Ray SDKにおいてAWS_XRAY_DAEMON_ADDRESS 環境変数を設定することが必要

>Amazon ECS で、X-Ray デーモンを実行するためには、 実行用のDocker イメージを作成し、それを Docker イメージリポジトリにアップロードして、Amazon ECS クラスターにデプロイできます。タスク定義ファイルでポートマッピングとネットワークモード設定を使用すると、アプリケーションがデーモンコンテナと通信できるようになります。 このためには、 ポートマッピング、リンク、および AWS_XRAY_DAEMON_ADDRESS 環境変数でホストポートを省略する設定が求められます。

## 質問16
>あなたはAWS専門のエンジニアとして、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリを構築しています。データセットは、1日おきにデータを処理し、結果をS3に保存するように設定されたコンシューマー機能を持つAmazon Kinesis Data Streamによってリアルタイムで収集されます。しかしながら、S3バケットに収集されたデータはAmazon Kinesis Data Streamデータに対して明らかに不足しています。検証したところIoTセンサーには問題はなく、正しく Amazon Kinesis Data Streamsにデータが送付されています。

>この問題の最も可能性の高い原因を選択してください。

*A: Amazon Kinesis Data Streamsのデフォルトのデータ保持期限を超過した* 

***
note:

* Kinesis Data Streamsのデフォルトのデータ保存期間は24時間、最長で7日間のため長期間保存するのは向いてない
* 一日置きにデータを取得するようになっているが、24時間のため前日のデータはなくなっている

> Amazon Kinesis Data Streams では、ストリームのデータレコードの保持期間の変更をサポートしています。Kinesis data stream はデータレコードの順序付けられたシーケンスで、リアルタイムで書き込みと読み取りができることが前提となっています。したがって、データレコードはシャードに一時的に保存されます。レコードが追加されてからアクセスできなくなるまでの期間は、保持期間と呼ばれます。デフォルトで Kinesis data stream は 24 時間レコードを保持し、最大値は 168 時間です。 

## 質問17
> あなたはアプリケーションエンジニアとして、DynamoDBテーブルから個々のアイテムを読み取り、EC2インスタンスで変更処理をするアプリケーションを構築しています。 このアプリケーションでは、1つのプロセスにおいてデータエントリが100~500程度発生しており、プロセス完了までに時間がかかるようです。マネージャーから必要な時間を短縮するように依頼されました。

> どのような設定方式で短縮することが可能ですか？

*A: DynamoDBのBatchGetItemAPIを利用する。* 

***
note:

* BatchGetItemAPIでDynamoDBから大量レコードを並列に取得できる
* 最大100アイテム (ただし、16MBを超えないアイテム数) を並列で取得してくれる DynamoDB 側で並列処理をしてくれる

> BatchGetItem オペレーションは、プライマリキーを使用して複数のテーブルから複数の項目の属性を返します。1 回のオペレーションで取り出すことができる項目の最大数は 100 です。また、取り出される項目の数は、1 MB のサイズ制限を受けます。レスポンスサイズの制限を超えた場合、またはテーブルのプロビジョニングされたスループットの超過や内部処理エラーが原因で一部の結果しか返されなかった場合はDynamoDB は UnprocessedKeys 値を返します。その際、オペレーションをやり直して次の項目から取得を再開することができます。

## 質問18
> あなたはエンジニアとして、画像共有システムを開発しています。このアプリケーションはユーザーが共有したい画像をS3にアップロードして共有します。ユーザーがS3バケットおよび他のAWSリソースにファイルをアップロードする度に、アクセス許可が設定された一時認証を利用した処理処理を実行します。

> この処理に必要なAPIコールを使用する必要がありますか？

*A: AssumeRole*

***
note:

* AssumeRoleを活用すると、本来持っていない権限を一時的に得られるため、「デプロイ時のみ特定の権限を得る」ことができる
* IAMユーザ自身には、AssumeRoleができる権限しか持たせない
* デプロイ用のIAMロールにAssumeRoleして、一時的なアクセスキーを入手する
* 一時的なアクセスキーを用いて、S3にデプロイする
* デプロイ時にS3が用いるIAMロールを指定する

>一時的なセキュリティ認証情報をリクエストするには、AWS API で AWS Security Token Serviceを使用できます。これには、AWS リソースへのアクセスを制御できる一時的セキュリティ認証情報を持つ、信頼されたユーザーを作成および提供するオペレーションが含まれます。 一時認証情報を引き受けるためにアプリケーションはAWS STS AssumeRole APIオペレーションを呼び出し、使用するロールのARNを渡します。この操作によって一時的な資格情報で新しいセッションが作成されます。

## 質問19
> A社では、IoTデータをキャプチャしてAmazon Kinesis Data Streamsに送信するモバイルアプリを構築しています。Amazon Kinesis Data Streamの開発担当者は、データフローのシャード数を調整して、データフローの転送速度の変化に適用させる対応を行っています。

> Amazon Kinesis Data Streamsのデータフローに応じた調整方法を選択してください。（2つ選択してください。）

*A: データフローの増加に対してシャードを分割する、データフローの減少に対してシャードをマージする*

***
note:

* Kinesis Data Streamsにオートスケーリング機能はありません。
* ただし、AWS Application Auto Scaling を利用して、Amazon Kinesis Data Stream に対してシャードを自動的に追加・削除するスケーリングポリシーを定義できる

## 質問20
> 開発者は非同期に呼び出されるLambda関数を使用するモバイルアプリケーションを開発しています。アプリケーションは、SQSキューによるポーリングをLambda関数が受け取って処理する方式であり、処理要求は2回再試行されるように設定しています。再試行に失敗した場合には失敗要因を分析するように失敗イベントを蓄積することが必要です。

> この要件を満たすために、利用するべき機能を選択してください。

*A: Lambdaデッドレターキュー*

***
note:

* デッドレターキューを使うとSQSで発行したキューでエラーになっているものを、自動的に別のキューや別の通知システムなどに連携することができる
* これをしないとエラーになったキューがずっとSQSに残り続けることになる

## 質問21
> あなたはソリューションアーキテクトとして、データアクセスにDynamoDBを使用して、可用性の高いWebアプリケーションを開発しています。 その際にインデックスを設定する必要がありますが、主キーと属性とを組合わせて複合キーを利用したいと考えています。

> データベースを作成するときに主キーを構成できる属性の最大数はいくつですか？

*A: 2*

***
note:

* DynamoDB のキーは三種類
* パーティションキー
  データをどのパーティションに配置するか決定する。
  各パーティションへのアクセスがなるべく均一になるようパーティションキーを設計すると良い。
* ソートキー
  ソートキーによってデータはパーティション内で並べ替えられて物理的に近くなるように配置される。
  QueryAPIではソートキーを指定して取り出すデータの範囲をフィルタできる。
  ソートキーの設定は任意。
* プライマリキー
 「パーティションキー」または「パーティションキーとソートキーの複合キー」のこと。
  プライマリキーによってデータは一意に識別される。
* DynamoDB は 2 種類の異なるプライマリキーを使う

## 質問23
> あなたはAPIコールでDynamoDBテーブルからデータを取得するサーバレスアーキテクチャを実装しています。このアプリケーションはLambdaプロキシ統合を使用してAPIゲートウェイと連携していますが、APIコールの応答とLambdaファンクションの実行状況をモニタリングする設定が必要です。

> このモニタリング要件を達成するCloudWatchの設定方法を選択してください。（2つ選択してください。）

*A: Latencyメトリックスを監視して、API呼び出しの全体的な応答性をみる、*<br >
*IntegrationLatencyメトリックスを監視して、バックエンドの応答性を測定する*

***
note:

* Amazon API Gateway はCloudWatch にメトリクスデータを毎分送信
* AWS/ApiGatewayの名前空間で保存される

メトリクス一覧
>* 4XXError：指定された期間に取得されたクライアント側エラーの数。
>* 5XXError：指定された期間に取得されたサーバー側エラーの数。
>* CacheHitCount：指定された期間内に API キャッシュから配信されたリクエストの数。
>* CacheMissCoun：API キャッシュが有効になっている特定の期間における、バックエンドから提供されたリクエストの数。
>* Count：指定された期間内の API リクエストの合計数。
>* IntegrationLatency：API Gateway がバックエンドにリクエストを中継してから、レスポンスを受け取るまでの時間。(中継してからのバックエンドの応答)
>* Latency：API Gateway がクライアントからリクエストを受け取ってから、クライアントにレスポンスを返すまでの時間。(バックエンドからクライアントまで全体の応答)

## 質問24
> A社は顧客管理向けのJavaアプリケーションをAWS上に構築しています。EC2インスタンスを利用してWEBサーバーを設置し、データベースシステムにはRDSを使用して顧客データを蓄積します。個人情報などの機密性の高いデータがやり取りされるため、KMSを利用して暗号化に使用するデータキーの暗号化されたコピーのみを返すAPI設定をアプリケーションに設定することになりました。暗号化処理では、Decrypt APIを呼び出してデータキーを復号化し、返されたプレーンテキストデータキーを使用して最終的にデータを暗号化します。

> 返されたプレーンテキストデータキーを使用して、最終的にデータを暗号化するために利用するべきKMS APIを選択してください。

*A: GenerateDataKeyWithoutPlainText*

***
note:

* 返答されたプレーンテキストデータキーを使用して最終的にデータを暗号化するためにはGenerateDataKeyWithoutPlaintextを利用
* データキー自体を作成するAPI
* DecryptやEncryptはその手段
* データキーの暗号化されたコピーのみを返すことを除いて、GenerateDataKeyと同じ処理

## 質問25
> ある企業は、WEBアプリケーションを運用するためにFargate起動タイプを使用するAmazon ECSクラスターを利用しています。 社内のセキュリティポリシーに準拠するために、データベース資格情報は環境変数を使用して提供される必要があります。 あなたはソリューションアーキテクトとして、認証情報が安全であること、およびクラスタ自体に平文で表示されないことを確認する必要があります。

> 次の方法の中で、最小の努力で実行することができる解決策を選択してください。

*A: AWS Systems Managerパラメータストアを利用して、データベースの設定データと機密データを保存し、KMSを利用して暗号化する。次にIAMロールをECSに設定してAWS Systems ManagerパラメータストアとKMSへのアクセス権限を付与する*

***
note:

* AWS Systems Manager パラメータストアは､設定データ管理と機密管理のための安全な階層型ストレージ
* Amazon ECSを使用すると、機密データをAWS Secrets ManagerまたはAWS Systems Managerパラメータストアに保存してから、そのコンテナ定義を参照することで、機密データをコンテナに注入することができる
* AWS Secrets ManagerとAWS Systems Managerパラメータストアの違いはよりセキュリティが高い
>Systems Manager (SSM)はAWSのリソースを可視化したり操作を自動化したりするサービス群で、 設定を持つParameter Storeはその一つ。値は暗号化して持つこともできる。 料金はかからない。
<br>SSMのParameter Storeと似たような別のAWSのサービスに Secrets Managerというのがあって、RDSなどと連携してLambdaによって定期的に新しい値を生成しローテーションさせることができる。 ただし料金がシークレットの件数($0.4/月)とAPIコール($0.05/10000回)でかかる。

## 質問27
>B社ではWEBアプリケーションのデータベースとしてRDS MySQLを利用しています。本日、このMySQLデータベースが応答しなくなる障害が発生し、あなたは対応に追われています。障害要因の解析のためには、障害の原因となったSQLステートメントのログ情報を確認することが必要です。

>この原因特定のために収集すべきログ取得方法はどれでしょうか。

*A: RDSのスロークエリログを有効にする*

***
note:

* MySQLではエラーログ、スロークエリログ、一般ログの三種類のログをモニタリングできる
* エラーログはデフォルトで生成され、実行に時間がかかったすべてのSQLステートメント内容を収集することができるのはスロークエリログ
* スロークエリログは、実行にlong_query_time秒以上かかるSQLステートメントで構成され、少なくともmin_examined_row_limit行を調べることで確認することができる
>■一般ログ：
mysqld の実行内容の一般的な記録です。サーバーは、クライアントが接続または接続解除したときに情報をこのログに書き込み、クライアントから受け取った各 SQL ステートメントをログに記録します。一般クエリーログは、クライアント側でエラーが疑われるとき、クライアントが mysqld に送信した内容を正確に知りたい場合に非常に役立つことがあります。

>■エラーログ
エラーログには mysqld が開始および停止された時期を示す情報と、サーバーが実行中に発生したあらゆるクリティカルエラーが格納されます。自動的にチェックまたは修復することが必要なテーブルが mysqld で検出された場合、エラーログに警告メッセージが書き込まれます。

>■スロークエリログ
スロークエリーログは、実行に要した時間が long_query_time 秒を超え、少なくとも min_examined_row_limit 行を検査する必要があった SQL ステートメントで構成されます。long_query_time の最小値およびデフォルト値は、それぞれ 0 および 10 です。値はマイクロ秒の精度まで指定できます。ファイルへのロギングの場合、時間はマイクロ秒の部分も含めて書き込まれます。テーブルへのロギングの場合、時間の整数部のみ書き込まれ、マイクロ秒の部分は無視されます。

## 質問28
>ある会社はSQSキューをLambdaが受け取って処理するサーバーレスアプリケーションによって、既存アプリケーションサーバーの業務処理を効率化しています。このLambda関数処理では、1分に1000リクエストが受信され、１つのリクエストを完了するのに100秒かかる高負荷な処理が予測されています。

>この高負荷処理を問題なく実行するための対策を選択してください。

*A: 上限値の制限オーバーに対してAWSに許可申請を行う*

***
note:

* デフォルトではLambdaは同一アカウントの同一リージョンで行える同時実行数の上限は1000
* 制限はリージョンごとに適用され、申請によって引き上げることができる
> Lambdaの同時実行数の計測は以下のように考えます。
> <br> 同時実行=（1秒あたりの呼び出し数）x（平均実行時間（秒）） 
<br>たとえば、 Lambda関数が平均10秒かかり、1秒あたり100個のイベントを発行するとします。次に、Lambda関数を1000同時に実行するため制限ぎりぎりとなります。今回のケースでは1分に1000リクエストが受信され、１つのリクエストを完了するのに100秒かかる高負荷が予測されており、1000の同時実行数を超える可能性が高いです。よって、AWSへのリクエストが必要となります。したがって、オプション2が正解となります。

## 質問29
>開発者はLambda関数とDynamoDBを連携させたモバイルアプリケーションを開発しています。このアプリケーションは、 DynamoDBテーブルへの新しいエントリを検出すると、Lambda関数によってエントリーされたデータを検証する検証プロセスを連携することが必要です。

>この要件を満たす最適で効率的なソリューション方式を選択してください。（2つ選択してください。）

*A: DynamoDBにSQSを設定して、データの新しい書き込み処理をトリガーにしてLambdaにメッセージを通知する*<br >
*AWS Lambda関数にDynamoDBストリームのARNを関連づける*

***
note:

* DynamoDBストリームはDynamoDBに加えられた変更を24時間保存するサービス
* DynamoDBストリームはDynamoDBに対する項目の追加、変更、削除をイベントとして検出できる
* Amazon DynamoDB は AWS Lambda と統合されているため、これを利用してDynamoDB テーブル内のデータ変更に対応するアプリケーションを構築する
> DynamoDB ストリーム を有効にした場合、書き込む AWS Lambda 関数にストリームの Amazon リソースネーム (ARN) を関連付ける設定を行います。これによって、テーブルの項目が変更されるとすぐに、新しいレコードがテーブルのストリームに表示されます。AWS Lambda はストリームをポーリングし、新しいストリームレコードを検出すると、Lambda 関数を同期的に呼び出すことができます。

## 質問30
>B社はAPI Gatewayを利用してLambdaを呼び出すサーバレスアプリケーションを構築しました。あなたはエンジニアとして、Lambda関数コードを圧縮して、Amazon S3にアップロードしてデプロイに向けて準備をしています。デプロイ手順をAWS上でなるべく自動化することが求められています。

>AWS SAMを利用したデプロイの自動化のために、選択すべきコマンドはどれでしょうか？ （2つ選択してください。）

*A: sam package ,sam deploy*

***
note:

* AWS SAMはLambda関数をローカルで実行しテストおよびデバッグができるフレームワーク
* ローカルで開発してSAMを利用してデプロイもできる
> AWS SAMは、AWS でサーバーレスアプリケーションを構築するために使用することができるオープンソースフレームワークです。AWS SAMはサーバーレスアプリケーションを定義するために使用する AWS SAM テンプレート仕様と、サーバーレスアプリケーションの構築、テスト、デプロイに使用する AWS SAM CLIで構成されています。 AWS SAMを利用してサーバーレスアプリケーションをローカルで開発およびテストした後、sam packageおよびsam deployコマンドを使用してアプリケーションのデプロイ方式を設定することができます。

## 質問33
>あなたはAWSでNode.jsアプリケーションを開発しています。現在はDynamoDBテーブルで読み込みキャパシティと書き込みキャパシティの設計を実施しているところです。以下の要件の設定が必要です。<br>
>・1秒間に30回の書き込み<br>
>・1秒間に20回の結果整合性のある読取処理<br>
>・両方の操作ですべてのアイテムのサイズが1KB<br>

>テーブルにプロビジョニングする必要がある最適な読み込みキャパシティーユニット（RCU）と書き込みキャパシティーユニット（WCU）の設定を選択してください。

*A: 10RCUと30WCU*

***
note:

* RCUは読み込みのキャパシティ 結果整合性の場合　1RCUあたり1秒間に4KBを2回　つまり8KB
* 強力な整合性の場合その1/2しか読み込めない
* 例えば10KBの項目を読み込んだら12KBに切り上げられ1.5RCU分消費される
* 1秒間に20回　結果整合性の場合2回のため10ユニットあればオッケー

* WCUは書き込みのキャパシティ 1WCUあたり1KBまでの1項目を書き込める
* 1KB以上の場合は1KBごとに切り上げてキャパを使うので1.5KBの場合は2WCU使う
* 1秒間に30回の書き込み × 1KB = 30WCU

```
■読み込みキャパシティーユニット（RCU）の計算方法

1 つの読み込みキャパシティーユニットは、最大サイズ 4 KB の項目について、1 秒あたり 1 回の強力な整合性のある読み込み、あるいは 1 秒あたり 2 回の結果整合性のある読み込みを表します。 例えば、10 ユニットのプロビジョニングされた読み取りキャパシティーでテーブルを作成するとします。これにより、最大 4 KB の項目について、1 秒あたり 10 回の強い整合性のある読み込み、または 20 回の結果的に整合性のある読み込みを行えます。 

4 KB を超える項目の読み込みには、より多くの読み取りキャパシティーユニットを消費します。たとえば、8 KB (4 KB × 2) の項目の強い整合性のある読み込みは、2 ユニットの読み込みキャパシティーユニットを消費します。同じ項目の結果的に整合性のある読み込みは、読み込みキャパシティーを 1 ユニットしか消費しません。 

したがって、RCUは10 ユニットのプロビジョニングされた読み取りキャパシティーでテーブルに対して、 20 回の結果的に整合性のある読み込みを行えるため、10RCUが正しい設定となります。 



■書き込みキャパシティーユニット（WCU）の計算方法

1 つの書き込みキャパシティーユニットは、最大サイズが 1 KB の項目について、1 秒あたり 1 回の書き込みを表します。

例えば、10 ユニットのプロビジョニングされた書き込みキャパシティーでテーブルを作成するとします。これにより、1 秒あたり最大でサイズが 1 KB の項目について、1 秒あたり 10 回の書き込みを行えます。

書き込みの項目サイズは、次の 1 KB の倍数に切り上げられます。たとえば、500 バイトの項目の書き込みは、1 KB の項目の書き込みと同じスループットを消費します。 

したがって、WCUは30 ユニットのプロビジョニングされた読み取りキャパシティーのテーブルに対して、 1 秒あたり最大でサイズ1 KB の項目について、1 秒あたり 30 回の書き込みを行えます。
```

## 質問34
> あなたはCI/CD環境を利用した開発を行っているエンジニアです。AWS CLIを使用してAWS CodeBuildによりプロジェクトをビルドする必要があります。 pintorapi.ymlファイルを設定してビルドコマンドを実行する設定を実施していますが、その際にビルド出力アーティファクトを暗号化する必要があります。

> ビルド出力アーティファクトを暗号化する設定方法を選択してください。

*A: 使用するカスタマーマスターキーを指定する*

***
note:
>AWS KMS カスタマーマスタキー (CMK) にアクセスする必要があります。デフォルトでは、CodeBuild はAmazon S3 の AWS Managed CMK を使用します。 この CMK を使用しない場合はユーザー自身で管理する CMK を作成して設定する必要があります。

## 質問35
>A社のシステム開発プロジェクトではソフトウェア配信プロセスを改善するために CI / CD環境を使用して、すべてのアプリケーションを構築し、Dockerコンテナとしてパッケージ化してデプロイすることを決定しました。 AWS CodePipelineとAWS CodeBuildによってプロジェクトのパイプラインが実行されると、Dockerイメージが保存されたECRにアクセスしてイメージをプッシュする処理が走ります。あなたがパイプラインを実行したところ認証エラーが発生したようです。

>このエラーの原因として最も可能性の高い問題を選択してください。

*A: CodeBuildサービスのIAMアクセス許可が間違っている*

***
note:
>IAMを利用した認証アクセスに失敗しています。AWS CodeBuildを利用してECRと連携させるためにはIAMによるECRに対するアクセス許可をCodeBuild側に設定する必要があります。

> CodeBuildを利用してDocker イメージを Amazon ECR リポジトリにプッシュするにはイメージのプッシュ先となる Amazon ECR レジストリに対して Docker クライアントを認証することが必要です。
